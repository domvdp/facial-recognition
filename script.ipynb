{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard dependicies\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import tensorflow dependicies - Functional API\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "ANC_PATH = os.path.join('..', 'data', 'anchor')\n",
    "POS_PATH = os.path.join('..', 'data', 'positive')\n",
    "NEG_PATH = os.path.join('..', 'data', ' negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cropping_boundaries(frame_dim, target_dim) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the pixel boundaries (width, height) for cropping the webcam frame.\n",
    "    \"\"\"\n",
    "    frame_dim_centre = int(frame_dim / 2)\n",
    "    half_target_dim = int(target_dim / 2)\n",
    "    \n",
    "    starting_pixel = frame_dim_centre - half_target_dim\n",
    "    ending_pixel = frame_dim_centre + half_target_dim\n",
    "    \n",
    "    return starting_pixel, ending_pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allow user to take pictures of their face (using laptop webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam(width_pixels, height_pixels, key):\n",
    "    # Establish connection to webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        val, frame = cap.read()\n",
    "\n",
    "        # Identify width and height of webcam frame\n",
    "        frame_width = frame.shape[0]\n",
    "        frame_height = frame.shape[1]\n",
    "\n",
    "        # Calculate boundaries for central cropping\n",
    "        start_width, end_width = calc_cropping_boundaries(frame_width, width_pixels)\n",
    "        start_height, end_height = calc_cropping_boundaries(frame_height, height_pixels)\n",
    "\n",
    "        # Crop frame so that captured images are same size as labelled images (dimensions 250 by 250 pixels)\n",
    "        cropped_frame = frame[start_width:end_width, start_height:end_height, :]\n",
    "        \n",
    "        if key == 'a':\n",
    "            # Capture anchor image\n",
    "            if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "                # Create unique file path for anchor image\n",
    "                img_path = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "\n",
    "                # Write anchor image to unique file path\n",
    "                cv2.imwrite(img_path, cropped_frame)\n",
    "                \n",
    "        if key == 'p':\n",
    "            # Capture positive image\n",
    "            if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "                # Create unique file path for positive image\n",
    "                img_path = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "\n",
    "                # Write anchor image to unique file path\n",
    "                cv2.imwrite(img_path, cropped_frame)\n",
    "\n",
    "        # Show image back to screen\n",
    "        cv2.imshow('Image cap', cropped_frame)\n",
    "\n",
    "        # Wait for a key press, and break loop if 'q' key is held\n",
    "        if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam\n",
    "    cap.release()\n",
    "\n",
    "    # Close image show frame\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired size of image [width, height] so that frame can be cropped\n",
    "width_pixels, height_pixels = [250, 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Anchor images with webcam\n",
    "webcam(width_pixels, height_pixels, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Positive images with webcam\n",
    "webcam(width_pixels, height_pixels, 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull image paths in a streaming fashion\n",
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(400)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(400)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Access the image paths from within the tensors\n",
    "# dir_test = anchor.as_numpy_iterator()\n",
    "\n",
    "# # Iterate through the image paths one at a time\n",
    "# dir_test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(file_path):\n",
    "    # Read image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    \n",
    "    # Decode image\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess(file_path):\n",
    "    \n",
    "    img = read_img(file_path)\n",
    "    \n",
    "    # Resize the image to be 105 x 105 x 3 (chose 105 as per Siamese Neural Network research paper)\n",
    "    img = tf.image.resize(img, (105, 105))\n",
    "    \n",
    "    # Scale the pixels to be values between 0 and 1\n",
    "    img = img / 255\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data) * 0.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data) * 0.7))\n",
    "test_data = data.take(round(len(data) * 0.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
